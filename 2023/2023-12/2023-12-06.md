
# 2023-12-06 Google Gemini's Dramatic Emergence

Today's most significant AI news is the launch of Google Gemini. While the majority seem to focus on Gemini's ability to outperform its competitors, it's interesting to delve into areas where Gemini may not excel and how Google addresses these shortcomings.
![Gemini models are natively multimodal](/2023/2023-12/attachments/2023_12_06_mulitdotal.png)

In the HellaSwag benchmark, Gemini Ultra's performance was not the best. The authors speculated this might be due to potential data contamination, identified after conducting several tests.
![hellaswag benchmark](/2023/2023-12/attachments/2023_12_06_hellaswag_benchmark.png)


Regarding translations into English, the authors did not provide a specific explanation for the model's performance.
![translation into english](/2023/2023-12/attachments/2023_12_06_translation.png)


Similarly, in the Science of MMMU, there was no explanation given.
![benchmark mmmu](/2023/2023-12/attachments/2023_12_06_mmmu.png)

When it comes to handling long contexts, the report indicates that Gemini models are trained with a 32K token capacity, effectively utilizing their context length. However, the report does not mention the model's capabilities for longer context retrieval over documents, particularly in section 5.2.2.
![long context](/2023/2023-12/attachments/2023_12_06_long_context.png)

In any case, it's exciting to witness another game-changing development in AI. The escalating competition among major players bring significantly benefit to the AI industry and end-users.





